{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0a243a-50e1-4d65-ae7f-b5f64549e868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/clip/clip.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import packaging\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import whisper\n",
    "import re\n",
    "import requests\n",
    "from pytubefix import YouTube\n",
    "from moviepy import VideoFileClip\n",
    "import subprocess\n",
    "import argparse\n",
    "#from pydub import AudioSegment\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import time\n",
    "from moviepy import VideoFileClip\n",
    "import shutil\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de8abaa-1b07-4037-85fb-3e6347d9f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video_from_youtube(url, output_path=\"input_video.mp4\"):\n",
    "    try:\n",
    "        yt = YouTube(url)\n",
    "        stream = yt.streams.filter(progressive=True, file_extension='mp4').get_highest_resolution()\n",
    "        stream.download(filename=output_path)\n",
    "        return output_path\n",
    "    except RuntimeError:\n",
    "        raise FileNotFoundError(\"File does not exist.\")\n",
    "\n",
    "def download_video_from_url(url, output_path=\"input_video.mp4\"):\n",
    "    if \"youtube.com\" in url or \"youtu.be\" in url:\n",
    "        return download_video_from_youtube(url, output_path)\n",
    "    \n",
    "    elif \"drive.google.com\" in url:\n",
    "        try:\n",
    "            file_id = url.split(\"/d/\")[1].split(\"/\")[0]\n",
    "        except IndexError:\n",
    "            raise ValueError(\"Google Drive link format incorrect.\")\n",
    "        d_url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
    "        r = requests.get(d_url, stream=True)\n",
    "        with open(output_path, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        return output_path\n",
    "\n",
    "    else: \n",
    "        r = requests.get(url, stream=True)\n",
    "        if r.status_code != 200:\n",
    "            raise ValueError(\"Could not download video from direct link.\")\n",
    "        with open(output_path, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        return output_path\n",
    "\n",
    "def convert_to_mp4(input_path, output_path=\"input_video.mp4\"):\n",
    "    try:\n",
    "        clip = VideoFileClip(input_path)\n",
    "        clip.write_videofile(output_path, codec='libx264')\n",
    "        clip.close()\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Video conversion failed: {e}\")\n",
    "\n",
    "def get_video_input(output_path=\"input_video.mp4\"):\n",
    "    print(\"Choose input method:\")\n",
    "    print(\"1. Upload local video file\")\n",
    "    print(\"2. Provide video URL (YouTube / Drive / MP4)\")\n",
    "    choice = input(\"Enter 1 or 2: \").strip()\n",
    "\n",
    "    if choice == \"1\":\n",
    "        file_path = input(\"Enter full path to your local video file: \").strip()\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(\"File does not exist.\")\n",
    "        print(\"Converting to MP4...\")\n",
    "        convert_to_mp4(file_path, output_path)\n",
    "        print(f\"Converted and saved to: {output_path}\")\n",
    "        return output_path\n",
    "\n",
    "    elif choice == \"2\":\n",
    "        url = input(\"Enter video URL: \").strip()\n",
    "        return download_video_from_url(url)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid choice. Please enter 1 or 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ac7d080-edb8-497f-9569-3de520ce565c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose input method:\n",
      "1. Upload local video file\n",
      "2. Provide video URL (YouTube / Drive / MP4)\n",
      "Converting to MP4...\n",
      "MoviePy - Building video input_video.mp4.\n",
      "MoviePy - Writing audio in input_videoTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video input_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready input_video.mp4\n",
      "Converted and saved to: input_video.mp4\n"
     ]
    }
   ],
   "source": [
    "video=get_video_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1a5ba6d-6500-4b03-a4b2-8dfee5cae8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmpeg_path = '/Users/mohalsahai/Desktop/Video Clipping/Python Packages/ffmpeg'\n",
    "\n",
    "def extract_audio(video_path, audio_path=\"audio.wav\"):\n",
    "    print(f\"Extracting audio from: {video_path}\")\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            ffmpeg_path, \"-y\", \"-i\", video_path, \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", audio_path\n",
    "        ], check=True)\n",
    "        print(f\"Audio saved to: {audio_path}\")\n",
    "        return audio_path\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise ValueError(f\"Audio extraction failed: {e}\")\n",
    "\n",
    "def extract_subtitles(video_path, subtitle_path=\"subtitles.srt\"):\n",
    "    print(\"Trying to extract subtitles...\")\n",
    "    result = subprocess.run(\n",
    "        [ffmpeg_path, \"-y\", \"-i\", video_path, \"-map\", \"0:s:0\", subtitle_path],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True\n",
    "    )\n",
    "    if \"Stream mapping:\" in result.stderr and os.path.exists(subtitle_path):\n",
    "        print(f\"Subtitles saved to: {subtitle_path}\")\n",
    "        return subtitle_path\n",
    "    else:\n",
    "        print(\"No subtitles found in the video.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a3b6c66-c176-4a76-8b79-fdbfb9e63e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting audio from: input_video.mp4\n",
      "Audio saved to: audio.wav\n",
      "Trying to extract subtitles...\n",
      "No subtitles found in the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version N-119686-gae0f71a387-tessus  https://evermeet.cx/ffmpeg/  Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with Apple clang version 17.0.0 (clang-1700.0.13.3)\n",
      "  configuration: --cc=/usr/bin/clang --prefix=/opt/ffmpeg --extra-version=tessus --enable-avisynth --enable-fontconfig --enable-gpl --enable-libaom --enable-libass --enable-libbluray --enable-libdav1d --enable-libfreetype --enable-libgsm --enable-libharfbuzz --enable-libmodplug --enable-libmp3lame --enable-libmysofa --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenh264 --enable-libopenjpeg --enable-libopus --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvmaf --enable-libvo-amrwbenc --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-version3 --pkg-config-flags=--static --disable-ffplay\n",
      "  libavutil      60.  3.100 / 60.  3.100\n",
      "  libavcodec     62.  3.101 / 62.  3.101\n",
      "  libavformat    62.  0.102 / 62.  0.102\n",
      "  libavdevice    62.  0.100 / 62.  0.100\n",
      "  libavfilter    11.  0.100 / 11.  0.100\n",
      "  libswscale      9.  0.100 /  9.  0.100\n",
      "  libswresample   6.  0.100 /  6.  0.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'input_video.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf61.7.100\n",
      "  Duration: 00:01:14.03, start: 0.000000, bitrate: 751 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 480x848, 616 kb/s, 29.96 fps, 29.96 tbr, 11984 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc61.19.100 libx264\n",
      "  Stream #0:1[0x2](und): Audio: mp3 (mp3float) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 127 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'audio.wav':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    ISFT            : Lavf62.0.102\n",
      "  Stream #0:0(und): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, stereo, s16, 512 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc62.3.101 pcm_s16le\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "[out#0/wav @ 0x7ff3ac715680] video:0KiB audio:4627KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.001646%\n",
      "size=    4627KiB time=00:01:14.03 bitrate= 512.0kbits/s speed=1.11e+03x elapsed=0:00:00.06    \n"
     ]
    }
   ],
   "source": [
    "audio=extract_audio(video)\n",
    "subtitles=extract_subtitles(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ea86d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Replace this with your actual path to ffmpeg\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/path/to/ffmpeg_folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4182cdae-ef81-4b52-bd5a-d22ea2939c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:06.120]  Welcome to the future of smart investing. Are you worried of charges eating out into\n",
      "[00:06.120 --> 00:14.840]  your investments in a ULIP? Now look no further. Star ULIP offers exceptionally low charges,\n",
      "[00:14.840 --> 00:21.380]  which are the premium allocation charges as low as 7% in the first year and just 6% from\n",
      "[00:21.380 --> 00:27.040]  year 2 to year 4. From fifth year, there are no allocation charges, thus ensuring that\n",
      "[00:27.040 --> 00:33.200]  all the money gets allocated and your money grows faster. That's not all. Even the female\n",
      "[00:33.200 --> 00:42.120]  lives get a 0.5% extra discount. And the best part is over the period of time, the charges\n",
      "[00:42.120 --> 00:48.440]  get returned back to you. Allocation charge, 2x of allocation charge is returned back,\n",
      "[00:48.440 --> 00:55.600]  3x of the admin charge and 2x or the 3x of the mortality charges are returned back to\n",
      "[00:55.600 --> 01:02.720]  the policyholder over a period of time. So Star ULIP is the best choice for smart investment.\n",
      "[01:02.720 --> 01:07.680]  Wish you all the best for lot of selling of Star ULIP. All the best.\n",
      "Detected language: en\n",
      "Full transcription:\n",
      "  Welcome to the future of smart investing. Are you worried of charges eating out into your investments in a ULIP? Now look no further. Star ULIP offers exceptionally low charges, which are the premium allocation charges as low as 7% in the first year and just 6% from year 2 to year 4. From fifth year, there are no allocation charges, thus ensuring that all the money gets allocated and your money grows faster. That's not all. Even the female lives get a 0.5% extra discount. And the best part is over the period of time, the charges get returned back to you. Allocation charge, 2x of allocation charge is returned back, 3x of the admin charge and 2x or the 3x of the mortality charges are returned back to the policyholder over a period of time. So Star ULIP is the best choice for smart investment. Wish you all the best for lot of selling of Star ULIP. All the best.\n",
      "[0.00 - 6.12]  Welcome to the future of smart investing. Are you worried of charges eating out into\n",
      "[6.12 - 14.84]  your investments in a ULIP? Now look no further. Star ULIP offers exceptionally low charges,\n",
      "[14.84 - 21.38]  which are the premium allocation charges as low as 7% in the first year and just 6% from\n",
      "[21.38 - 27.04]  year 2 to year 4. From fifth year, there are no allocation charges, thus ensuring that\n",
      "[27.04 - 33.20]  all the money gets allocated and your money grows faster. That's not all. Even the female\n",
      "[33.20 - 42.12]  lives get a 0.5% extra discount. And the best part is over the period of time, the charges\n",
      "[42.12 - 48.44]  get returned back to you. Allocation charge, 2x of allocation charge is returned back,\n",
      "[48.44 - 55.60]  3x of the admin charge and 2x or the 3x of the mortality charges are returned back to\n",
      "[55.60 - 62.72]  the policyholder over a period of time. So Star ULIP is the best choice for smart investment.\n",
      "[62.72 - 67.68]  Wish you all the best for lot of selling of Star ULIP. All the best.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import whisper\n",
    "import subprocess\n",
    "\n",
    "# --- Custom FFmpeg Path ---\n",
    "ffmpeg_path = '/Users/mohalsahai/Desktop/Video Clipping/Python Packages/ffmpeg'\n",
    "\n",
    "# --- Add to PATH so whisper can find it ---\n",
    "os.environ[\"PATH\"] += os.pathsep + os.path.dirname(ffmpeg_path)\n",
    "\n",
    "# --- Whisper Transcription ---\n",
    "model = whisper.load_model(\"medium\")\n",
    "result = model.transcribe(\"audio.wav\", verbose=True, task='transcribe', language='en', fp16=False)\n",
    "\n",
    "# --- Output ---\n",
    "print(\"Detected language:\", result['language'])\n",
    "print(\"Full transcription:\\n\", result['text'])\n",
    "\n",
    "timestamped_transcript=\"\"\n",
    "for segment in result[\"segments\"]:\n",
    "    timestamped_transcript+=f\"[{segment['start']:.2f} - {segment['end']:.2f}] {segment['text']}\\n\"\n",
    "    print(f\"[{segment['start']:.2f} - {segment['end']:.2f}] {segment['text']}\")\n",
    "\n",
    "# --- Save Full Transcript ---\n",
    "with open(\"transcript.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(result[\"text\"])\n",
    "\n",
    "# --- Save SRT File ---\n",
    "def save_srt(segments, path=\"transcript.srt\"):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, seg in enumerate(segments):\n",
    "            start = seg['start']\n",
    "            end = seg['end']\n",
    "            text = seg['text']\n",
    "            f.write(f\"{i+1}\\n\")\n",
    "            f.write(f\"{format_time(start)} --> {format_time(end)}\\n\")\n",
    "            f.write(f\"{text.strip()}\\n\\n\")\n",
    "\n",
    "# --- Format Time for SRT ---\n",
    "def format_time(seconds):\n",
    "    h = int(seconds // 3600)\n",
    "    m = int((seconds % 3600) // 60)\n",
    "    s = seconds % 60\n",
    "    return f\"{h:02}:{m:02}:{s:06.3f}\".replace(\".\", \",\")\n",
    "\n",
    "save_srt(result['segments'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56e8ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def find_similar_transcript_segments(text_query, transcript_segments, top_k=5):\n",
    "    query_embedding = embedder.encode(text_query, convert_to_tensor=True)\n",
    "    texts = [seg[\"text\"] for seg in transcript_segments]\n",
    "    text_embeddings = embedder.encode(texts, convert_to_tensor=True, batch_size=32)\n",
    "\n",
    "    similarities = util.cos_sim(query_embedding, text_embeddings)[0]\n",
    "    ranked = sorted(zip(transcript_segments, similarities), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    results = []\n",
    "    for segment, score in ranked[:top_k]:\n",
    "        results.append({\n",
    "            \"text\": segment[\"text\"],\n",
    "            \"start\": segment[\"start\"],\n",
    "            \"end\": segment[\"end\"],\n",
    "            \"similarity\": float(score)\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6d6cb4",
   "metadata": {},
   "source": [
    "Chatbot with UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d677cd9c-e61d-44de-a055-7d7eb30e549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "import threading\n",
    "import queue\n",
    "import re\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "llm = OllamaLLM(model='gemma3:12b')\n",
    "\n",
    "# Template for general queries\n",
    "general_template = \"\"\"\n",
    "You are Vivi, an expert and friendly video assistant chatbot.\n",
    "\n",
    "You are having an ongoing conversation with the user. You have access to a full transcript of a video. If the user’s question is about the video, answer helpfully and refer to timestamps if relevant.\n",
    "\n",
    "If the question is general and not related to the video, just respond helpfully like a normal assistant. You can use your general knowledge to help the user even if it’s unrelated to the transcript.\n",
    "\n",
    "---\n",
    "Conversation History:\n",
    "{context}\n",
    "\n",
    "---\n",
    "Full Transcript of the Video:\n",
    "{transcript}\n",
    "\n",
    "---\n",
    "User:\n",
    "{question}\n",
    "\n",
    "---\n",
    "Vivi:\n",
    "\"\"\"\n",
    "\n",
    "# Template for topic extraction\n",
    "topic_template = \"\"\"\n",
    "You are an expert video analysis assistant. Given the transcript of a video with timestamps, identify the major topics discussed and provide their corresponding timestamp ranges. Return the result as a list of topics, each with a brief description and its start and end timestamps.\n",
    "\n",
    "Transcript:\n",
    "{transcript}\n",
    "\n",
    "Return the result in the following format:\n",
    "- Topic: [Brief description]\n",
    "  Timestamps: [start_time] - [end_time]\n",
    "\"\"\"\n",
    "\n",
    "prompt_general = ChatPromptTemplate.from_template(general_template)\n",
    "prompt_topic = ChatPromptTemplate.from_template(topic_template)\n",
    "chain_general = prompt_general | llm\n",
    "chain_topic = prompt_topic | llm\n",
    "\n",
    "# FFmpeg-based video clipping function\n",
    "def clip_video(video_path, start_time, end_time, output_path=None):\n",
    "    \"\"\"\n",
    "    Clip a video from start_time to end_time using FFmpeg, ensuring audio is included.\n",
    "    \n",
    "    Args:\n",
    "        video_path (str): Path to the input video.\n",
    "        start_time (float): Start time in seconds.\n",
    "        end_time (float): End time in seconds.\n",
    "        output_path (str): Path to save the clipped video. If None, generates a default name.\n",
    "    \n",
    "    Returns:\n",
    "        str: Success message with output path or error message.\n",
    "    \"\"\"\n",
    "    ffmpeg_path = '/Users/mohalsahai/Desktop/Video Clipping/Python Packages/ffmpeg'\n",
    "    try:\n",
    "        if not os.path.exists(video_path):\n",
    "            return f\"Error: Video file {video_path} does not exist.\"\n",
    "        \n",
    "        if output_path is None:\n",
    "            base, ext = os.path.splitext(video_path)\n",
    "            output_path = f\"{base}_clip_{int(start_time)}_{int(end_time)}.mp4\"\n",
    "        \n",
    "        # Calculate duration\n",
    "        duration = end_time - start_time\n",
    "        \n",
    "        # FFmpeg command: -ss for start, -t for duration, -c:v copy for video, -c:a aac for audio\n",
    "        command = [\n",
    "            ffmpeg_path, \"-y\",  # Overwrite output if exists\n",
    "            \"-i\", video_path,   # Input file\n",
    "            \"-ss\", str(start_time),  # Start time\n",
    "            \"-t\", str(duration),     # Duration\n",
    "            \"-c:v\", \"copy\",     # Copy video stream without re-encoding\n",
    "            \"-c:a\", \"aac\",      # Re-encode audio to AAC\n",
    "            \"-strict\", \"-2\",    # Allow experimental codecs if needed\n",
    "            output_path         # Output file\n",
    "        ]\n",
    "        \n",
    "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "        if result.stderr:\n",
    "            print(f\"FFmpeg warning/info: {result.stderr}\")\n",
    "        return f\"Video clip saved to {output_path}\"\n",
    "    \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"Error clipping video: FFmpeg failed with {e.stderr}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error clipping video: {str(e)}\"\n",
    "\n",
    "def start_chat_ui(transcript_segments, full_transcript_text):\n",
    "    context = \"\"\n",
    "    response_queue = queue.Queue()\n",
    "    video_path = video  # Use the video variable from Cell 3\n",
    "\n",
    "    def is_video_clipping_query(query):\n",
    "        return query.lower().startswith(\"video clipping:\")\n",
    "\n",
    "    def extract_query(query):\n",
    "        match = re.match(r\"Video Clipping:\\\\s*(.+)\", query, re.IGNORECASE)\n",
    "        return match.group(1).strip() if match else query\n",
    "\n",
    "    def get_major_topics():\n",
    "        try:\n",
    "            response = chain_topic.invoke({\"transcript\": full_transcript_text})\n",
    "            topics = []\n",
    "            lines = response.split(\"\\n\")\n",
    "            current_topic = None\n",
    "            for line in lines:\n",
    "                if line.startswith(\"- Topic:\"):\n",
    "                    current_topic = {\"description\": line.replace(\"- Topic:\", \"\").strip()}\n",
    "                elif line.startswith(\"  Timestamps:\") and current_topic:\n",
    "                    times = line.replace(\"  Timestamps:\", \"\").strip()\n",
    "                    # Clean timestamps by removing brackets and splitting\n",
    "                    times = re.sub(r'[\\[\\]]', '', times).split(\" - \")\n",
    "                    if len(times) == 2:\n",
    "                        try:\n",
    "                            start_time = float(times[0].strip())\n",
    "                            end_time = float(times[1].strip())\n",
    "                            current_topic[\"start\"] = start_time\n",
    "                            current_topic[\"end\"] = end_time\n",
    "                            topics.append(current_topic)\n",
    "                            current_topic = None\n",
    "                        except ValueError as e:\n",
    "                            print(f\"Skipping invalid timestamp in line '{line}': {str(e)}\")\n",
    "                            current_topic = None\n",
    "                            continue\n",
    "            return topics if topics else [{\"description\": \"No valid topics extracted\", \"start\": 0, \"end\": 0}]\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting topics: {str(e)}\")\n",
    "            return [{\"description\": f\"Error extracting topics: {str(e)}\", \"start\": 0, \"end\": 0}]\n",
    "\n",
    "    def find_most_similar_topic(query, topics):\n",
    "        if not topics:\n",
    "            return None\n",
    "        query_embedding = embedder.encode(query)\n",
    "        topic_descriptions = [topic[\"description\"] for topic in topics]\n",
    "        topic_embeddings = embedder.encode(topic_descriptions)\n",
    "        similarities = util.cos_sim(query_embedding, topic_embeddings)[0]\n",
    "        max_idx = similarities.argmax()\n",
    "        return topics[max_idx], float(similarities[max_idx])\n",
    "\n",
    "    def send_message():\n",
    "        nonlocal context\n",
    "        user_input = user_entry.get()\n",
    "        if user_input.strip().lower() == \"exit\":\n",
    "            root.destroy()\n",
    "            return\n",
    "\n",
    "        chat_display.insert(tk.END, f\"User: {user_input}\\n\")\n",
    "        user_entry.delete(0, tk.END)\n",
    "\n",
    "        def run_bot():\n",
    "            try:\n",
    "                if is_video_clipping_query(user_input):\n",
    "                    query = extract_query(user_input)\n",
    "                    topics = get_major_topics()\n",
    "                    if not topics or \"Error\" in topics[0][\"description\"]:\n",
    "                        response_queue.put((topics[0][\"description\"], []))\n",
    "                        return\n",
    "\n",
    "                    best_topic, similarity = find_most_similar_topic(query, topics)\n",
    "                    if not best_topic or similarity < 0.1:\n",
    "                        response_queue.put((\"No relevant topic found for the video.\", []))\n",
    "                        return\n",
    "\n",
    "                    result = clip_video(\n",
    "                        video_path,\n",
    "                        best_topic[\"start\"],\n",
    "                        best_topic[\"end\"],\n",
    "                        output_path=f\"clipped_{int(best_topic['start'])}_{int(best_topic['end'])}.mp4\"\n",
    "                    )\n",
    "                    response = f\"{result}\\nTopic: {best_topic['description']}\\nTimestamps: {best_topic['start']:.2f} - {best_topic['end']:.2f}\\nSimilarity: {similarity:.2f}\"\n",
    "                    response_queue.put((response, []))\n",
    "                else:\n",
    "                    top_segments = find_similar_transcript_segments(user_input, transcript_segments, top_k=3)\n",
    "                    response = chain_general.invoke({\n",
    "                        \"context\": context,\n",
    "                        \"question\": user_input,\n",
    "                        \"transcript\": full_transcript_text,\n",
    "                    })\n",
    "                    response_queue.put((response, top_segments))\n",
    "            except Exception as e:\n",
    "                response_queue.put((f\"Error: {str(e)}\", []))\n",
    "\n",
    "        def check_queue():\n",
    "            try:\n",
    "                response, top_segments = response_queue.get_nowait()\n",
    "                chat_display.insert(tk.END, f\"Vivi: {response}\\n\")\n",
    "                if top_segments:\n",
    "                    chat_display.insert(tk.END, \"Relevant segments:\\n\" + \"\\n\".join(\n",
    "                        [f\"[{seg['start']:.2f} - {seg['end']:.2f}]: {seg['text']}\" for seg in top_segments]) + \"\\n\")\n",
    "                chat_display.yview(tk.END)\n",
    "                nonlocal context\n",
    "                context += f\"\\nUser: {user_input}\\nAI: {response}\\n\"\n",
    "            except queue.Empty:\n",
    "                root.after(100, check_queue)\n",
    "\n",
    "        threading.Thread(target=run_bot, daemon=True).start()\n",
    "        root.after(100, check_queue)\n",
    "\n",
    "    def on_closing():\n",
    "        for thread in threading.enumerate()[1:]:\n",
    "            thread.join(timeout=1.0)\n",
    "        root.destroy()\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Vivi Video Chatbot\")\n",
    "    chat_display = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=80, height=30, font=(\"Arial\", 12))\n",
    "    chat_display.pack(padx=10, pady=10)\n",
    "    user_entry = tk.Entry(root, font=(\"Arial\", 12))\n",
    "    user_entry.pack(fill=tk.X, padx=10, pady=(0, 10))\n",
    "    user_entry.bind(\"<Return>\", lambda e: send_message())\n",
    "    send_btn = tk.Button(root, text=\"Send\", font=(\"Arial\", 12), command=send_message)\n",
    "    send_btn.pack(pady=(0, 10))\n",
    "    chat_display.insert(tk.END, \"Welcome to the Vivi Video Chatbot! Type 'exit' to quit.\\nFor video clipping, use 'Video Clipping: {Query}'.\\n\")\n",
    "    chat_display.yview(tk.END)\n",
    "    root.protocol(\"WM_DELETE_WINDOW\", on_closing)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb02f9de-5b83-46a7-ac6d-f6928c38d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_transcript_with_timestamps(segments):\n",
    "    lines = []\n",
    "    for seg in segments:\n",
    "        start = format_time(seg['start'])\n",
    "        end = format_time(seg['end'])\n",
    "        text = seg['text'].strip()\n",
    "        lines.append(f\"[{start} - {end}] {text}\")\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2c3304a-c578-4f34-8c2f-d79699c1c066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFmpeg warning/info: ffmpeg version N-119686-gae0f71a387-tessus  https://evermeet.cx/ffmpeg/  Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with Apple clang version 17.0.0 (clang-1700.0.13.3)\n",
      "  configuration: --cc=/usr/bin/clang --prefix=/opt/ffmpeg --extra-version=tessus --enable-avisynth --enable-fontconfig --enable-gpl --enable-libaom --enable-libass --enable-libbluray --enable-libdav1d --enable-libfreetype --enable-libgsm --enable-libharfbuzz --enable-libmodplug --enable-libmp3lame --enable-libmysofa --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenh264 --enable-libopenjpeg --enable-libopus --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvmaf --enable-libvo-amrwbenc --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-version3 --pkg-config-flags=--static --disable-ffplay\n",
      "  libavutil      60.  3.100 / 60.  3.100\n",
      "  libavcodec     62.  3.101 / 62.  3.101\n",
      "  libavformat    62.  0.102 / 62.  0.102\n",
      "  libavdevice    62.  0.100 / 62.  0.100\n",
      "  libavfilter    11.  0.100 / 11.  0.100\n",
      "  libswscale      9.  0.100 /  9.  0.100\n",
      "  libswresample   6.  0.100 /  6.  0.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'input_video.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf61.7.100\n",
      "  Duration: 00:01:14.03, start: 0.000000, bitrate: 751 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 480x848, 616 kb/s, 29.96 fps, 29.96 tbr, 11984 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc61.19.100 libx264\n",
      "  Stream #0:1[0x2](und): Audio: mp3 (mp3float) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 127 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #0:1 -> #0:1 (mp3 (mp3float) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp4, to 'clipped_6_21.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf62.0.102\n",
      "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 480x848, q=2-31, 616 kb/s, 29.96 fps, 29.96 tbr, 11984 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc61.19.100 libx264\n",
      "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc62.3.101 aac\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "[out#0/mp4 @ 0x7fb152815200] video:1057KiB audio:241KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 1.204066%\n",
      "frame=  393 fps=0.0 q=-1.0 Lsize=    1314KiB time=00:00:15.26 bitrate= 705.2kbits/s speed=59.6x elapsed=0:00:00.25    \n",
      "[aac @ 0x7fb151f04e00] Qavg: 711.409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start_chat_ui(result[\"segments\"], timestamped_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25618e31-2076-4fa2-8039-29094d6ddf68",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timestamped_transcript' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtimestamped_transcript\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'timestamped_transcript' is not defined"
     ]
    }
   ],
   "source": [
    "print(timestamped_transcript)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
