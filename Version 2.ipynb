{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0a243a-50e1-4d65-ae7f-b5f64549e868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/clip/clip.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import packaging\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import whisper\n",
    "import re\n",
    "import requests\n",
    "from pytubefix import YouTube\n",
    "from moviepy import VideoFileClip\n",
    "import subprocess\n",
    "import argparse\n",
    "#from pydub import AudioSegment\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import time\n",
    "from moviepy import VideoFileClip\n",
    "import shutil\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de8abaa-1b07-4037-85fb-3e6347d9f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video_from_youtube(url, output_path=\"input_video.mp4\"):\n",
    "    try:\n",
    "        yt = YouTube(url)\n",
    "        stream = yt.streams.filter(progressive=True, file_extension='mp4').get_highest_resolution()\n",
    "        stream.download(filename=output_path)\n",
    "        return output_path\n",
    "    except RuntimeError:\n",
    "        raise FileNotFoundError(\"File does not exist.\")\n",
    "\n",
    "def download_video_from_url(url, output_path=\"input_video.mp4\"):\n",
    "    if \"youtube.com\" in url or \"youtu.be\" in url:\n",
    "        return download_video_from_youtube(url, output_path)\n",
    "    \n",
    "    elif \"drive.google.com\" in url:\n",
    "        try:\n",
    "            file_id = url.split(\"/d/\")[1].split(\"/\")[0]\n",
    "        except IndexError:\n",
    "            raise ValueError(\"Google Drive link format incorrect.\")\n",
    "        d_url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
    "        r = requests.get(d_url, stream=True)\n",
    "        with open(output_path, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        return output_path\n",
    "\n",
    "    else: \n",
    "        r = requests.get(url, stream=True)\n",
    "        if r.status_code != 200:\n",
    "            raise ValueError(\"Could not download video from direct link.\")\n",
    "        with open(output_path, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        return output_path\n",
    "\n",
    "def convert_to_mp4(input_path, output_path=\"input_video.mp4\"):\n",
    "    try:\n",
    "        clip = VideoFileClip(input_path)\n",
    "        clip.write_videofile(output_path, codec='libx264')\n",
    "        clip.close()\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Video conversion failed: {e}\")\n",
    "\n",
    "def get_video_input(output_path=\"input_video.mp4\"):\n",
    "    print(\"Choose input method:\")\n",
    "    print(\"1. Upload local video file\")\n",
    "    print(\"2. Provide video URL (YouTube / Drive / MP4)\")\n",
    "    choice = input(\"Enter 1 or 2: \").strip()\n",
    "\n",
    "    if choice == \"1\":\n",
    "        file_path = input(\"Enter full path to your local video file: \").strip()\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(\"File does not exist.\")\n",
    "        print(\"Converting to MP4...\")\n",
    "        convert_to_mp4(file_path, output_path)\n",
    "        print(f\"Converted and saved to: {output_path}\")\n",
    "        return output_path\n",
    "\n",
    "    elif choice == \"2\":\n",
    "        url = input(\"Enter video URL: \").strip()\n",
    "        return download_video_from_url(url)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid choice. Please enter 1 or 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ac7d080-edb8-497f-9569-3de520ce565c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose input method:\n",
      "1. Upload local video file\n",
      "2. Provide video URL (YouTube / Drive / MP4)\n",
      "Converting to MP4...\n",
      "MoviePy - Building video input_video.mp4.\n",
      "MoviePy - Writing audio in input_videoTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video input_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready input_video.mp4\n",
      "Converted and saved to: input_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "video=get_video_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1a5ba6d-6500-4b03-a4b2-8dfee5cae8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmpeg_path = '/Users/mohalsahai/Desktop/Video Clipping/Python Packages/ffmpeg'\n",
    "\n",
    "def extract_audio(video_path, audio_path=\"audio.wav\"):\n",
    "    print(f\"Extracting audio from: {video_path}\")\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            ffmpeg_path, \"-y\", \"-i\", video_path, \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", audio_path\n",
    "        ], check=True)\n",
    "        print(f\"Audio saved to: {audio_path}\")\n",
    "        return audio_path\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise ValueError(f\"Audio extraction failed: {e}\")\n",
    "\n",
    "def extract_subtitles(video_path, subtitle_path=\"subtitles.srt\"):\n",
    "    print(\"Trying to extract subtitles...\")\n",
    "    result = subprocess.run(\n",
    "        [ffmpeg_path, \"-y\", \"-i\", video_path, \"-map\", \"0:s:0\", subtitle_path],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True\n",
    "    )\n",
    "    if \"Stream mapping:\" in result.stderr and os.path.exists(subtitle_path):\n",
    "        print(f\"Subtitles saved to: {subtitle_path}\")\n",
    "        return subtitle_path\n",
    "    else:\n",
    "        print(\"No subtitles found in the video.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a3b6c66-c176-4a76-8b79-fdbfb9e63e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting audio from: input_video.mp4\n",
      "Audio saved to: audio.wav\n",
      "Trying to extract subtitles...\n",
      "No subtitles found in the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version N-119686-gae0f71a387-tessus  https://evermeet.cx/ffmpeg/  Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with Apple clang version 17.0.0 (clang-1700.0.13.3)\n",
      "  configuration: --cc=/usr/bin/clang --prefix=/opt/ffmpeg --extra-version=tessus --enable-avisynth --enable-fontconfig --enable-gpl --enable-libaom --enable-libass --enable-libbluray --enable-libdav1d --enable-libfreetype --enable-libgsm --enable-libharfbuzz --enable-libmodplug --enable-libmp3lame --enable-libmysofa --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenh264 --enable-libopenjpeg --enable-libopus --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvmaf --enable-libvo-amrwbenc --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-version3 --pkg-config-flags=--static --disable-ffplay\n",
      "  libavutil      60.  3.100 / 60.  3.100\n",
      "  libavcodec     62.  3.101 / 62.  3.101\n",
      "  libavformat    62.  0.102 / 62.  0.102\n",
      "  libavdevice    62.  0.100 / 62.  0.100\n",
      "  libavfilter    11.  0.100 / 11.  0.100\n",
      "  libswscale      9.  0.100 /  9.  0.100\n",
      "  libswresample   6.  0.100 /  6.  0.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'input_video.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf61.7.100\n",
      "  Duration: 00:01:14.03, start: 0.000000, bitrate: 751 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 480x848, 616 kb/s, 29.96 fps, 29.96 tbr, 11984 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc61.19.100 libx264\n",
      "  Stream #0:1[0x2](und): Audio: mp3 (mp3float) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 127 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'audio.wav':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    ISFT            : Lavf62.0.102\n",
      "  Stream #0:0(und): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, stereo, s16, 512 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc62.3.101 pcm_s16le\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "[out#0/wav @ 0x7fecaf70d340] video:0KiB audio:4627KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.001646%\n",
      "size=    4627KiB time=00:01:14.03 bitrate= 512.0kbits/s speed=1.11e+03x elapsed=0:00:00.06    \n"
     ]
    }
   ],
   "source": [
    "audio=extract_audio(video)\n",
    "subtitles=extract_subtitles(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ea86d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Replace this with your actual path to ffmpeg\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/path/to/ffmpeg_folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4182cdae-ef81-4b52-bd5a-d22ea2939c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:06.120]  Welcome to the future of smart investing. Are you worried of charges eating out into\n",
      "[00:06.120 --> 00:14.840]  your investments in a ULIP? Now look no further. Star ULIP offers exceptionally low charges,\n",
      "[00:14.840 --> 00:21.380]  which are the premium allocation charges as low as 7% in the first year and just 6% from\n",
      "[00:21.380 --> 00:27.040]  year 2 to year 4. From fifth year, there are no allocation charges, thus ensuring that\n",
      "[00:27.040 --> 00:33.200]  all the money gets allocated and your money grows faster. That's not all. Even the female\n",
      "[00:33.200 --> 00:42.120]  lives get a 0.5% extra discount. And the best part is over the period of time, the charges\n",
      "[00:42.120 --> 00:48.440]  get returned back to you. Allocation charge, 2x of allocation charge is returned back,\n",
      "[00:48.440 --> 00:55.600]  3x of the admin charge and 2x or the 3x of the mortality charges are returned back to\n",
      "[00:55.600 --> 01:02.720]  the policyholder over a period of time. So Star ULIP is the best choice for smart investment.\n",
      "[01:02.720 --> 01:07.680]  Wish you all the best for lot of selling of Star ULIP. All the best.\n",
      "Detected language: en\n",
      "Full transcription:\n",
      "  Welcome to the future of smart investing. Are you worried of charges eating out into your investments in a ULIP? Now look no further. Star ULIP offers exceptionally low charges, which are the premium allocation charges as low as 7% in the first year and just 6% from year 2 to year 4. From fifth year, there are no allocation charges, thus ensuring that all the money gets allocated and your money grows faster. That's not all. Even the female lives get a 0.5% extra discount. And the best part is over the period of time, the charges get returned back to you. Allocation charge, 2x of allocation charge is returned back, 3x of the admin charge and 2x or the 3x of the mortality charges are returned back to the policyholder over a period of time. So Star ULIP is the best choice for smart investment. Wish you all the best for lot of selling of Star ULIP. All the best.\n",
      "[0.00 - 6.12]  Welcome to the future of smart investing. Are you worried of charges eating out into\n",
      "[6.12 - 14.84]  your investments in a ULIP? Now look no further. Star ULIP offers exceptionally low charges,\n",
      "[14.84 - 21.38]  which are the premium allocation charges as low as 7% in the first year and just 6% from\n",
      "[21.38 - 27.04]  year 2 to year 4. From fifth year, there are no allocation charges, thus ensuring that\n",
      "[27.04 - 33.20]  all the money gets allocated and your money grows faster. That's not all. Even the female\n",
      "[33.20 - 42.12]  lives get a 0.5% extra discount. And the best part is over the period of time, the charges\n",
      "[42.12 - 48.44]  get returned back to you. Allocation charge, 2x of allocation charge is returned back,\n",
      "[48.44 - 55.60]  3x of the admin charge and 2x or the 3x of the mortality charges are returned back to\n",
      "[55.60 - 62.72]  the policyholder over a period of time. So Star ULIP is the best choice for smart investment.\n",
      "[62.72 - 67.68]  Wish you all the best for lot of selling of Star ULIP. All the best.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import whisper\n",
    "import subprocess\n",
    "\n",
    "# --- Custom FFmpeg Path ---\n",
    "ffmpeg_path = '/Users/mohalsahai/Desktop/Video Clipping/Python Packages/ffmpeg'\n",
    "\n",
    "# --- Add to PATH so whisper can find it ---\n",
    "os.environ[\"PATH\"] += os.pathsep + os.path.dirname(ffmpeg_path)\n",
    "\n",
    "# --- Whisper Transcription ---\n",
    "model = whisper.load_model(\"medium\")\n",
    "result = model.transcribe(\"audio.wav\", verbose=True, task='transcribe', language='en', fp16=False)\n",
    "\n",
    "# --- Output ---\n",
    "print(\"Detected language:\", result['language'])\n",
    "print(\"Full transcription:\\n\", result['text'])\n",
    "\n",
    "timestamped_transcript=\"\"\n",
    "for segment in result[\"segments\"]:\n",
    "    timestamped_transcript+=f\"[{segment['start']:.2f} - {segment['end']:.2f}] {segment['text']}\\n\"\n",
    "    print(f\"[{segment['start']:.2f} - {segment['end']:.2f}] {segment['text']}\")\n",
    "\n",
    "# --- Save Full Transcript ---\n",
    "with open(\"transcript.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(result[\"text\"])\n",
    "\n",
    "# --- Save SRT File ---\n",
    "def save_srt(segments, path=\"transcript.srt\"):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, seg in enumerate(segments):\n",
    "            start = seg['start']\n",
    "            end = seg['end']\n",
    "            text = seg['text']\n",
    "            f.write(f\"{i+1}\\n\")\n",
    "            f.write(f\"{format_time(start)} --> {format_time(end)}\\n\")\n",
    "            f.write(f\"{text.strip()}\\n\\n\")\n",
    "\n",
    "# --- Format Time for SRT ---\n",
    "def format_time(seconds):\n",
    "    h = int(seconds // 3600)\n",
    "    m = int((seconds % 3600) // 60)\n",
    "    s = seconds % 60\n",
    "    return f\"{h:02}:{m:02}:{s:06.3f}\".replace(\".\", \",\")\n",
    "\n",
    "save_srt(result['segments'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56e8ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def find_similar_transcript_segments(text_query, transcript_segments, top_k=5):\n",
    "    query_embedding = embedder.encode(text_query, convert_to_tensor=True)\n",
    "    texts = [seg[\"text\"] for seg in transcript_segments]\n",
    "    text_embeddings = embedder.encode(texts, convert_to_tensor=True, batch_size=32)\n",
    "\n",
    "    similarities = util.cos_sim(query_embedding, text_embeddings)[0]\n",
    "    ranked = sorted(zip(transcript_segments, similarities), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    results = []\n",
    "    for segment, score in ranked[:top_k]:\n",
    "        results.append({\n",
    "            \"text\": segment[\"text\"],\n",
    "            \"start\": segment[\"start\"],\n",
    "            \"end\": segment[\"end\"],\n",
    "            \"similarity\": float(score)\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6d6cb4",
   "metadata": {},
   "source": [
    "Chatbot with UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d677cd9c-e61d-44de-a055-7d7eb30e549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "import threading\n",
    "import queue\n",
    "import re\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "import subprocess\n",
    "import tempfile\n",
    "\n",
    "llm = OllamaLLM(model='gemma3', base_url='http://localhost:11434')\n",
    "\n",
    "# Template for general queries\n",
    "general_template = \"\"\"\n",
    "You are Vivi, an expert and friendly video assistant chatbot.\n",
    "\n",
    "You are having an ongoing conversation with the user. You have access to a full transcript of a video. If the user’s question is about the video, answer helpfully and refer to timestamps if relevant.\n",
    "\n",
    "If the question is general and not related to the video, just respond helpfully like a normal assistant. You can use your general knowledge to help the user even if it’s unrelated to the transcript.\n",
    "\n",
    "---\n",
    "Conversation History:\n",
    "{context}\n",
    "\n",
    "---\n",
    "Full Transcript of the Video:\n",
    "{transcript}\n",
    "\n",
    "---\n",
    "User:\n",
    "{question}\n",
    "\n",
    "---\n",
    "Vivi:\n",
    "\"\"\"\n",
    "\n",
    "# Template for extracting timestamps for video clipping\n",
    "clipping_template = \"\"\"\n",
    "You are an expert video analysis assistant. Given a user query and the transcript of a video with timestamps, identify all timestamp ranges where the video content is relevant to the query. Return the result as a list of timestamp ranges (start and end times in seconds) and a brief explanation of why each range is relevant.\n",
    "\n",
    "Return timestamps as plain numbers with two decimal places (e.g., 31.00, 45.00) without brackets or other characters. Ensure the format is consistent. Ensure end_time is greater than start_time and both are non-negative.\n",
    "\n",
    "Query: {query}\n",
    "Transcript: {transcript}\n",
    "\n",
    "Return the result in the following format:\n",
    "- Range: start_time - end_time\n",
    "  Relevance: [Brief explanation of why this range is relevant to the query]\n",
    "\"\"\"\n",
    "\n",
    "prompt_general = ChatPromptTemplate.from_template(general_template)\n",
    "prompt_clipping = ChatPromptTemplate.from_template(clipping_template)\n",
    "chain_general = prompt_general | llm\n",
    "chain_clipping = prompt_clipping | llm\n",
    "\n",
    "# FFmpeg-based video clipping function\n",
    "def clip_video(video_path, start_time, end_time, output_path=None):\n",
    "    \"\"\"\n",
    "    Clip a video from start_time to end_time using FFmpeg with re-encoding for sync.\n",
    "    \n",
    "    Args:\n",
    "        video_path (str): Path to the input video.\n",
    "        start_time (float): Start time in seconds.\n",
    "        end_time (float): End time in seconds.\n",
    "        output_path (str): Path to save the clipped video. If None, generates a default name.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (Success message or error message, output_path or None)\n",
    "    \"\"\"\n",
    "    ffmpeg_path = '/Users/mohalsahai/Desktop/Video Clipping/Python Packages/ffmpeg'\n",
    "    try:\n",
    "        if not os.path.exists(video_path):\n",
    "            return f\"Error: Video file {video_path} does not exist.\", None\n",
    "        \n",
    "        if output_path is None:\n",
    "            base, ext = os.path.splitext(video_path)\n",
    "            output_path = f\"{base}_clip_{int(start_time)}_{int(end_time)}.mp4\"\n",
    "        \n",
    "        # Validate duration\n",
    "        duration = end_time - start_time\n",
    "        if duration <= 0:\n",
    "            return f\"Error: Invalid duration ({duration}s) for range {start_time}-{end_time}.\", None\n",
    "        \n",
    "        # FFmpeg command with re-encoding for consistent frame rate and sync\n",
    "        command = [\n",
    "            ffmpeg_path, \"-y\",  # Overwrite output if exists\n",
    "            \"-i\", video_path,   # Input file\n",
    "            \"-ss\", str(start_time),  # Start time\n",
    "            \"-t\", str(duration),     # Duration\n",
    "            \"-c:v\", \"libx264\",  # Re-encode video to H.264\n",
    "            \"-c:a\", \"aac\",      # Re-encode audio to AAC\n",
    "            \"-r\", \"30\",         # Force 30 fps (adjust to match source video if needed)\n",
    "            \"-vsync\", \"1\",      # Synchronize video to audio\n",
    "            \"-af\", \"anull\",     # Ensure audio stream exists\n",
    "            \"-preset\", \"fast\",  # Encoding speed\n",
    "            \"-movflags\", \"+faststart\",  # Optimize for QuickTime\n",
    "            output_path         # Output file\n",
    "        ]\n",
    "        \n",
    "        result = subprocess.run(command, capture_output=True, text=True)\n",
    "        if result.returncode != 0:\n",
    "            return f\"Error clipping video: FFmpeg failed with {result.stderr}\", None\n",
    "        return f\"Video clip saved to {output_path}\", output_path\n",
    "    \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"Error clipping video: FFmpeg failed with {e.stderr}\", None\n",
    "    except Exception as e:\n",
    "        return f\"Error clipping video: {str(e)}\", None\n",
    "\n",
    "# Function to concatenate multiple video clips\n",
    "def concatenate_videos(video_paths, output_path):\n",
    "    \"\"\"\n",
    "    Concatenate multiple video clips into a single video using FFmpeg concat filter.\n",
    "    \n",
    "    Args:\n",
    "        video_paths (list): List of paths to video clips to concatenate.\n",
    "        output_path (str): Path to save the concatenated video.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (Success message or error message, output_path or None)\n",
    "    \"\"\"\n",
    "    ffmpeg_path = '/Users/mohalsahai/Desktop/Video Clipping/Python Packages/ffmpeg'\n",
    "    try:\n",
    "        if not video_paths:\n",
    "            return \"Error: No video clips provided for concatenation.\", None\n",
    "        \n",
    "        # Build FFmpeg command using concat filter\n",
    "        command = [\n",
    "            ffmpeg_path, \"-y\"  # Overwrite output if exists\n",
    "        ]\n",
    "        \n",
    "        # Add input files\n",
    "        for path in video_paths:\n",
    "            command.extend([\"-i\", path])\n",
    "        \n",
    "        # Use concat filter\n",
    "        filter_complex = f\"[0:v][0:a][1:v][1:a]\" + \"\".join(f\"[{i}:v][{i}:a]\" for i in range(2, len(video_paths)))\n",
    "        filter_complex += f\"concat=n={len(video_paths)}:v=1:a=1[v][a]\"\n",
    "        \n",
    "        command.extend([\n",
    "            \"-filter_complex\", filter_complex,\n",
    "            \"-map\", \"[v]\",      # Map concatenated video\n",
    "            \"-map\", \"[a]\",      # Map concatenated audio\n",
    "            \"-c:v\", \"libx264\",  # Re-encode video to H.264\n",
    "            \"-c:a\", \"aac\",      # Re-encode audio to AAC\n",
    "            \"-preset\", \"fast\",  # Encoding speed\n",
    "            \"-movflags\", \"+faststart\",  # Optimize for QuickTime\n",
    "            output_path         # Output file\n",
    "        ])\n",
    "        \n",
    "        result = subprocess.run(command, capture_output=True, text=True)\n",
    "        if result.returncode != 0:\n",
    "            return f\"Error concatenating videos: FFmpeg failed with {result.stderr}\", None\n",
    "        return f\"Concatenated video saved to {output_path}\", output_path\n",
    "    \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"Error concatenating videos: FFmpeg failed with {e.stderr}\", None\n",
    "    except Exception as e:\n",
    "        return f\"Error concatenating videos: {str(e)}\", None\n",
    "\n",
    "def start_chat_ui(transcript_segments, full_transcript_text):\n",
    "    context = \"\"\n",
    "    response_queue = queue.Queue()\n",
    "    video_path = video  # Use the video variable from Cell 3\n",
    "\n",
    "    def is_video_clipping_query(query):\n",
    "        return query.lower().startswith(\"video clipping:\")\n",
    "\n",
    "    def extract_query(query):\n",
    "        match = re.match(r\"Video Clipping:\\\\s*(.+)\", query, re.IGNORECASE)\n",
    "        return match.group(1).strip() if match else query\n",
    "\n",
    "    def get_relevant_timestamps(query):\n",
    "        try:\n",
    "            response = chain_clipping.invoke({\"query\": query, \"transcript\": full_transcript_text})\n",
    "            ranges = []\n",
    "            lines = response.split(\"\\n\")\n",
    "            current_range = None\n",
    "            for line in lines:\n",
    "                if line.startswith(\"- Range:\"):\n",
    "                    # Clean the timestamp string by removing non-numeric characters except decimal points and hyphens\n",
    "                    time_str = line.replace(\"- Range:\", \"\").strip()\n",
    "                    # Use regex to extract two numbers separated by a hyphen\n",
    "                    match = re.match(r\"[\\[\\s]*([\\d\\.]+)\\s*-\\s*([\\d\\.]+)[\\]\\s]*\", time_str)\n",
    "                    if match and len(match.groups()) == 2:\n",
    "                        try:\n",
    "                            start = float(match.group(1))\n",
    "                            end = float(match.group(2))\n",
    "                            if end <= start or start < 0 or end < 0:\n",
    "                                return [{\"start\": 0, \"end\": 0, \"relevance\": f\"Invalid timestamp range: {start}-{end}\"}]\n",
    "                            current_range = {\"start\": start, \"end\": end}\n",
    "                        except ValueError as e:\n",
    "                            return [{\"start\": 0, \"end\": 0, \"relevance\": f\"Error parsing timestamps: {str(e)}\"}]\n",
    "                    else:\n",
    "                        return [{\"start\": 0, \"end\": 0, \"relevance\": f\"Invalid timestamp format in LLM response: {time_str}\"}]\n",
    "                elif line.startswith(\"  Relevance:\") and current_range:\n",
    "                    current_range[\"relevance\"] = line.replace(\"  Relevance:\", \"\").strip()\n",
    "                    ranges.append(current_range)\n",
    "                    current_range = None\n",
    "            if not ranges:\n",
    "                return [{\"start\": 0, \"end\": 0, \"relevance\": \"No relevant timestamps found for the query.\"}]\n",
    "            return ranges\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error connecting to LLM server: {str(e)}. Please ensure the Ollama server is running on localhost:11434 or check the network configuration.\"\n",
    "            return [{\"start\": 0, \"end\": 0, \"relevance\": error_msg}]\n",
    "\n",
    "    def send_message():\n",
    "        nonlocal context\n",
    "        user_input = user_entry.get()\n",
    "        if user_input.strip().lower() == \"exit\":\n",
    "            root.destroy()\n",
    "            return\n",
    "\n",
    "        chat_display.insert(tk.END, f\"User: {user_input}\\n\")\n",
    "        user_entry.delete(0, tk.END)\n",
    "\n",
    "        def run_bot():\n",
    "            try:\n",
    "                if is_video_clipping_query(user_input):\n",
    "                    query = extract_query(user_input)\n",
    "                    ranges = get_relevant_timestamps(query)\n",
    "                    if not ranges or \"Error\" in ranges[0][\"relevance\"]:\n",
    "                        response_queue.put((ranges[0][\"relevance\"], []))\n",
    "                        return\n",
    "\n",
    "                    # Create temporary clips\n",
    "                    temp_clips = []\n",
    "                    temp_dir = tempfile.gettempdir()\n",
    "                    response_parts = []\n",
    "                    for i, r in enumerate(ranges):\n",
    "                        temp_output = os.path.join(temp_dir, f\"temp_clip_{i}_{int(r['start'])}_{int(r['end'])}.mp4\")\n",
    "                        result, clip_path = clip_video(\n",
    "                            video_path,\n",
    "                            r[\"start\"],\n",
    "                            r[\"end\"],\n",
    "                            output_path=temp_output\n",
    "                        )\n",
    "                        if \"Error\" in result:\n",
    "                            # Clean up any created clips and return error\n",
    "                            for clip in temp_clips:\n",
    "                                if os.path.exists(clip):\n",
    "                                    os.unlink(clip)\n",
    "                            response_queue.put((f\"{result}\\nTemporary clips retained in {temp_dir} for debugging.\", []))\n",
    "                            return\n",
    "                        temp_clips.append(clip_path)\n",
    "                        response_parts.append(\n",
    "                            f\"Segment {i+1}: {r['start']:.2f} - {r['end']:.2f}\\nRelevance: {r['relevance']}\"\n",
    "                        )\n",
    "                    \n",
    "                    # Concatenate clips\n",
    "                    base, ext = os.path.splitext(video_path)\n",
    "                    final_output = f\"{base}_concatenated.mp4\"\n",
    "                    concat_result, concat_path = concatenate_videos(temp_clips, final_output)\n",
    "                    \n",
    "                    # Clean up temporary clips\n",
    "                    for clip in temp_clips:\n",
    "                        if os.path.exists(clip):\n",
    "                            os.unlink(clip)\n",
    "                    \n",
    "                    if \"Error\" in concat_result:\n",
    "                        response_queue.put((f\"{concat_result}\\nTemporary clips retained in {temp_dir} for debugging.\", []))\n",
    "                        return\n",
    "                    \n",
    "                    # Prepare response\n",
    "                    response = f\"{concat_result}\\n\\nIncluded segments:\\n\" + \"\\n\".join(response_parts)\n",
    "                    response_queue.put((response, []))\n",
    "                else:\n",
    "                    top_segments = find_similar_transcript_segments(user_input, transcript_segments, top_k=3)\n",
    "                    response = chain_general.invoke({\n",
    "                        \"context\": context,\n",
    "                        \"question\": user_input,\n",
    "                        \"transcript\": full_transcript_text,\n",
    "                    })\n",
    "                    response_queue.put((response, top_segments))\n",
    "            except Exception as e:\n",
    "                response_queue.put((f\"Error: {str(e)}\\nTemporary clips (if any) retained in {tempfile.gettempdir()} for debugging.\", []))\n",
    "\n",
    "        def check_queue():\n",
    "            try:\n",
    "                response, top_segments = response_queue.get_nowait()\n",
    "                chat_display.insert(tk.END, f\"Vivi: {response}\\n\")\n",
    "                if top_segments:\n",
    "                    chat_display.insert(tk.END, \"Relevant segments:\\n\" + \"\\n\".join(\n",
    "                        [f\"[{seg['start']:.2f} - {seg['end']:.2f}]: {seg['text']}\" for seg in top_segments]) + \"\\n\")\n",
    "                chat_display.yview(tk.END)\n",
    "                nonlocal context\n",
    "                context += f\"\\nUser: {user_input}\\nAI: {response}\\n\"\n",
    "            except queue.Empty:\n",
    "                root.after(100, check_queue)\n",
    "\n",
    "        threading.Thread(target=run_bot, daemon=True).start()\n",
    "        root.after(100, check_queue)\n",
    "\n",
    "    def on_closing():\n",
    "        for thread in threading.enumerate()[1:]:\n",
    "            thread.join(timeout=1.0)\n",
    "        root.destroy()\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Vivi Video Chatbot\")\n",
    "    chat_display = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=80, height=30, font=(\"Arial\", 12))\n",
    "    chat_display.pack(padx=10, pady=10)\n",
    "    user_entry = tk.Entry(root, font=(\"Arial\", 12))\n",
    "    user_entry.pack(fill=tk.X, padx=10, pady=(0, 10))\n",
    "    user_entry.bind(\"<Return>\", lambda e: send_message())\n",
    "    send_btn = tk.Button(root, text=\"Send\", font=(\"Arial\", 12), command=send_message)\n",
    "    send_btn.pack(pady=(0, 10))\n",
    "    chat_display.insert(tk.END, \"Welcome to the Vivi Video Chatbot! Type 'exit' to quit.\\nFor video clipping, use 'Video Clipping: {Query}'.\\n\")\n",
    "    chat_display.yview(tk.END)\n",
    "    root.protocol(\"WM_DELETE_WINDOW\", on_closing)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb02f9de-5b83-46a7-ac6d-f6928c38d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_transcript_with_timestamps(segments):\n",
    "    lines = []\n",
    "    for seg in segments:\n",
    "        start = format_time(seg['start'])\n",
    "        end = format_time(seg['end'])\n",
    "        text = seg['text'].strip()\n",
    "        lines.append(f\"[{start} - {end}] {text}\")\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c3304a-c578-4f34-8c2f-d79699c1c066",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start_chat_ui(result[\"segments\"], timestamped_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25618e31-2076-4fa2-8039-29094d6ddf68",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timestamped_transcript' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtimestamped_transcript\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'timestamped_transcript' is not defined"
     ]
    }
   ],
   "source": [
    "print(timestamped_transcript)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
